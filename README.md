# Awesome-Unified-Multimodal

All the papers listed in this project come from my usual reading.
If you have found some new and interesting papers, I would appreciate it if you let me know! You can contact me via my email address: niuyuwei04@gmail.com

+ Chameleon: Mixed-Modal Early-Fusion Foundation Models
  [![Static Badge](https://img.shields.io/badge/2405.09818-red?logo=arxiv)](https://arxiv.org/abs/2405.09818)

+ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model
  [![Static Badge](https://img.shields.io/badge/2408.11039-red?logo=arxiv)](https://arxiv.org/abs/2408.11039)

+ Show-o: One Single Transformer to Unify Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2408.12528-red?logo=arxiv)](https://arxiv.org/abs/2408.12528)

+ VILA-U: A Unified Foundation Model Integrating Visual Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2409.04429-red?logo=arxiv)](https://arxiv.org/abs/2409.04429)

+ Emu2: Generative Multimodal Models are In-Context Learners
  [![Static Badge](https://img.shields.io/badge/2312.13286-red?logo=arxiv)](https://arxiv.org/abs/2312.13286)

+ MIO: A Foundation Model on Multimodal Tokens
  [![Static Badge](https://img.shields.io/badge/2409.17692-red?logo=arxiv)](https://arxiv.org/abs/2409.17692)

+ MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling
  [![Static Badge](https://img.shields.io/badge/2410.10798-red?logo=arxiv)](https://arxiv.org/abs/2410.10798)

+ Emu3: Next-Token Prediction is All You Need
  [![Static Badge](https://img.shields.io/badge/2409.18869-red?logo=arxiv)](https://arxiv.org/abs/2409.18869)

+ PUMA: Empowering Unified MLLM with Multi-granular Visual Generation
  [![Static Badge](https://img.shields.io/badge/2410.13861-red?logo=arxiv)](https://arxiv.org/abs/2410.13861)

+ Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2410.13848-red?logo=arxiv)](https://arxiv.org/abs/2410.13848)

+ JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2411.07975-red?logo=arxiv)](https://arxiv.org/abs/2411.07975)

+ MUSE-VL: Modeling Unified VLM through Semantic Discrete Encoding
  [![Static Badge](https://img.shields.io/badge/2411.17762-red?logo=arxiv)](https://arxiv.org/abs/2411.17762)

+ TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2412.03069-red?logo=arxiv)](https://arxiv.org/abs/2412.03069)

+ Liquid: Language Models are Scalable Multi-modal Generators
  [![Static Badge](https://img.shields.io/badge/2412.04332-red?logo=arxiv)](https://arxiv.org/abs/2412.04332)
    
