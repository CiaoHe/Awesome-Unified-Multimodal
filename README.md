# Awesome-Unified-Multimodal

All the papers listed in this project come from my usual reading.
If you have found some new and interesting papers, I would appreciate it if you let me know! You can contact me via my email address: niuyuwei04@gmail.com

 **Transfusion**: Predict the Next Token and Diffuse Images with One Multi-Modal Model [![Static Badge](https://img.shields.io/badge/2408.11039-red?logo=arxiv)](https://arxiv.org/abs/2408.11039)  
 **Show-o**: One Single Transformer to Unify Multimodal Understanding and Generation  [![Static Badge](https://img.shields.io/badge/2408.12528-red?logo=arxiv)](https://arxiv.org/abs/2408.12528)  
 **VILA-U**: a Unified Foundation Model Integrating Visual Understanding and Generation  [![Static Badge](https://img.shields.io/badge/2409.04429-red?logo=arxiv)](https://arxiv.org/abs/2409.04429)  
 **Janus**: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation  [![Static Badge](https://img.shields.io/badge/2410.13848-red?logo=arxiv)](https://arxiv.org/abs/2410.13848)  
 **TokenFlow**: Unified Image Tokenizer for Multimodal Understanding and Generation [![Static Badge](https://img.shields.io/badge/2412.03069-red?logo=arxiv)](https://arxiv.org/abs/2412.03069)    
 **Liquid**: Language Models are Scalable Multi-modal Generators [![Static Badge](https://img.shields.io/badge/2412.04332-red?logo=arxiv)](https://arxiv.org/abs/2412.04332)  
    
